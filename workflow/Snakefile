# libraries
import yaml
import pandas as pd
import os
from snakemake.utils import validate, min_version
import json
import csv
import sys
import subprocess

##### set minimum snakemake version #####
min_version("6.0.3")

SDIR = os.path.realpath(os.path.dirname(srcdir("Snakefile")))
shell.prefix(f"set -eo pipefail;")

##### setup report #####
report: "report/workflow.rst"

##### load config and annotation #####
configfile: os.path.join("config","config.yaml")

##### get  LOLA resources if needed #####
LOLA_path = os.path.join("resources", config["project_name"], "LOLA")
if not os.path.exists(LOLA_path):
    print("start downloading and unpacking LOLA resources")
    os.makedirs(LOLA_path, exist_ok=True)
    
    LOLA_path = os.path.abspath(LOLA_path)
    
    URL_Core='http://big.databio.org/regiondb/LOLACoreCaches_180412.tgz'
    URL_Ext='http://big.databio.org/regiondb/LOLAExtCaches_170206.tgz'
    
    # download
    getCore_str = 'wget --directory-prefix={} {}'.format(LOLA_path, URL_Core)
    getExt_str = 'wget --directory-prefix={} {}'.format(LOLA_path, URL_Ext)
    
    subprocess.run(getCore_str, shell=True)
    subprocess.run(getExt_str, shell=True)
    
    # unpack
    unpackCore_str = 'tar zxvf {} -C {}'.format(os.path.join(LOLA_path, 'LOLACoreCaches_180412.tgz'), LOLA_path)
    unpackExt_str = 'tar zxvf {} -C {}'.format(os.path.join(LOLA_path, 'LOLAExtCaches_170206.tgz'), LOLA_path)
    
    subprocess.run(unpackCore_str, shell=True)
    subprocess.run(unpackExt_str, shell=True)
    
    # remove
    removeCore_str = 'rm -f {}'.format(os.path.join(LOLA_path, 'LOLACoreCaches_180412.tgz'))
    removeExt_str = 'rm -f {}'.format(os.path.join(LOLA_path, 'LOLAExtCaches_170206.tgz'))
    
    subprocess.run(removeCore_str, shell=True)
    subprocess.run(removeExt_str, shell=True)
    
    print("finished downloading and unpacking LOLA resources")


### get annotations 
### for three data types: query genes, query regions and background regions (to be converted to genes)
annot = pd.read_csv(config["annotation"], index_col='name')

# genes
genes = annot.loc[annot['features_path'].str.endswith('.txt'),:]
genes_dict = genes.to_dict('index')
# print(genes_dict) # for testing

# regions
regions = annot.loc[annot['features_path'].str.endswith('.bed'),:]
regions_dict = regions.to_dict('index')
# print(regions_dict) # for testing

# background regions
background_region_df = regions.loc[:,['background_name', 'background_path']]
background_region_df = background_region_df.drop_duplicates()
background_regions_dict = background_region_df.set_index('background_name').to_dict('index')
# print(background_regions_dict) # for testing

# databases
great_dbs = [db.replace(" ","_") for db in config["great_dbs"]]

##### set global variables
result_path = os.path.join(config["result_path"],'enrichment_analysis')


##### target rules #####
rule all:
    input:
        ### region enrichment analyses
        expand(os.path.join(result_path, '{region_set}', 'LOLA','{db}','{region_set}_{db}.csv'), region_set=regions_dict.keys(), db=config["lola_dbs"]),
        expand(os.path.join(result_path, '{region_set}', 'LOLA','{db}','{region_set}_{db}.png'), region_set=regions_dict.keys(), db=config["lola_dbs"]),
        expand(os.path.join(result_path, '{region_set}', 'GREAT','{db}','{region_set}_{db}.csv'), region_set=regions_dict.keys(), db=great_dbs),
        expand(os.path.join(result_path, '{region_set}', 'GREAT','{db}','{region_set}_{db}.png'), region_set=regions_dict.keys(), db=great_dbs),
        expand(os.path.join(result_path, '{background_region_set}', 'GREAT','genes.txt'), background_region_set=background_regions_dict.keys()),
        expand(os.path.join(result_path, '{region_set}', 'GSEApy','{db}','{region_set}_{db}.csv'), region_set=regions_dict.keys(), db=config["enrichr_dbs"]),
        expand(os.path.join(result_path, '{region_set}', 'GSEApy','{db}','{region_set}_{db}.png'), region_set=regions_dict.keys(), db=config["enrichr_dbs"]),
        # gene enrichment analyses
        expand(os.path.join(result_path, '{gene_set}', 'GSEApy','{db}','{gene_set}_{db}.csv'), gene_set=genes_dict.keys(), db=config["enrichr_dbs"]),
        expand(os.path.join(result_path, '{gene_set}', 'GSEApy','{db}','{gene_set}_{db}.png'), gene_set=genes_dict.keys(), db=config["enrichr_dbs"]),
        # summaries
        expand(os.path.join(result_path,'{group}','{tool}','{db}','{group}_{db}_summary.png'),group=annot["group"].unique(), tool='GSEApy', db=config["enrichr_dbs"]),
        expand(os.path.join(result_path,'{group}','{tool}','{db}','{group}_{db}_summary.png'),group=regions["group"].unique(), tool='GREAT', db=great_dbs),
        expand(os.path.join(result_path,'{group}','{tool}','{db}','{group}_{db}_summary.png'),group=regions["group"].unique(), tool='LOLA', db=config["lola_dbs"]),
        # config
        envs = expand(os.path.join(config["result_path"],'envs','enrichment_analysis','{env}.yaml'),env=['region_enrichment_analysis','gene_enrichment_analysis','visualization']),
        configs = os.path.join(config["result_path"],'configs','enrichment_analysis','{}_config.yaml'.format(config["project_name"])),
        annotations = os.path.join(config["result_path"],'configs','enrichment_analysis','{}_annot.csv'.format(config["project_name"])),
    params:
        partition=config.get("partition"),
    threads: config.get("threads", 1)
    resources:
        mem_mb=config.get("mem", "16000"),
    log:
        os.path.join("logs","rules","all.log")
        
# download enrichr databases to local json files using GSEApy
rule load_enrichr_databases:
    output:
        result_file=os.path.join("resources", config["project_name"],"{db}.json"),
    params:
        database = lambda w: "{}".format(w.db),
        partition=config.get("partition"),
    threads: config.get("threads", 1)
    resources:
        mem_mb=config.get("mem", "16000"),
    conda:
        "envs/gene_enrichment_analysis.yaml",
    log:
        "logs/rules/get_Enrichr_databases_{db}.log"
    script:
        "scripts/get_Enrichr_databases_GSEApy.py"

##### load rules #####
include: os.path.join("rules", "common.smk")
include: os.path.join("rules", "enrichment_analysis.smk")
include: os.path.join("rules", "aggregate.smk")
include: os.path.join("rules", "envs_export.smk")

